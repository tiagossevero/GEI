{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aea681-2477-45f5-9ffe-1cb8f6cb1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "#Import libs python\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "\n",
    "#Import libs internas\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "from hooks.hdfs.hdfs_helper import HdfsHelper\n",
    "from jobs.job_base_config import BaseETLJobClass\n",
    "\n",
    "import poc_helper\n",
    "poc_helper.load_env(\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf8a1f-48e4-4c57-a162-c839c8e3a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_session(profile: str, dynamic_allocation_enabled: bool = True) -> utils.DBASparkAppSession:\n",
    "    \"\"\"Generates DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"tsevero_gei_calculo\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "session = get_session(profile='efd_t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00777b24-69dc-4a6e-ba6f-4e11cd534937",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "session.sparkSession.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d8bf8-a229-46d4-8c06-850c68566574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para an√°lise e visualiza√ß√£o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, date\n",
    "from decimal import Decimal\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Acesso ao SparkSession\n",
    "spark = session.sparkSession\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SISTEMA DE AN√ÅLISE FISCAL - PROCESSAMENTO NFe/CTe\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb6645-d9a0-4600-8a23-8d6fd4bb330e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 3: PAR√ÇMETROS DE ENTRADA\n",
    "# ===================================================================\n",
    "# DEFINA AQUI OS PAR√ÇMETROS DA AN√ÅLISE\n",
    "\n",
    "# Per√≠odo de an√°lise (formato YYYYMM)\n",
    "PERIODO_INICIO = 202001  # Janeiro/2020\n",
    "PERIODO_FIM = 202509     # Setembro/2025\n",
    "\n",
    "# Lista de CNPJs a serem analisados (cadastro)\n",
    "# Se vazio, busca da tabela de cadastro\n",
    "CNPJS_ANALISE = ['32372396000194', '46909678000192']  # Exemplo: ['12345678000190', '98765432000110']\n",
    "\n",
    "# Se quiser buscar de uma tabela espec√≠fica:\n",
    "TABELA_CADASTRO = \"usr_sat_ods.vw_ods_contrib\"  # Ajuste conforme sua tabela\n",
    "CAMPO_CNPJ_CADASTRO = \"nu_cnpj\"  # Campo que cont√©m o CNPJ\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PAR√ÇMETROS DA AN√ÅLISE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Per√≠odo: {PERIODO_INICIO} at√© {PERIODO_FIM}\")\n",
    "print(f\"Tabela Cadastro: {TABELA_CADASTRO}\")\n",
    "print(f\"CNPJs espec√≠ficos: {len(CNPJS_ANALISE) if CNPJS_ANALISE else 'Todos da tabela de cadastro'}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17742d-e289-45f6-9fcc-d2fc7b14f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 4: CARREGAR CNPJS DO CADASTRO\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CARREGANDO CNPJS DO CADASTRO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if CNPJS_ANALISE:\n",
    "    # Usar lista manual\n",
    "    df_cadastro = spark.createDataFrame(\n",
    "        [(cnpj,) for cnpj in CNPJS_ANALISE], \n",
    "        [\"cnpj\"]\n",
    "    )\n",
    "    print(f\"‚úì Usando {len(CNPJS_ANALISE)} CNPJs fornecidos manualmente\")\n",
    "else:\n",
    "    # Buscar da tabela\n",
    "    query_cadastro = f\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        REGEXP_REPLACE(TRIM(CAST({CAMPO_CNPJ_CADASTRO} AS STRING)), '[^0-9]', '') AS cnpj\n",
    "    FROM {TABELA_CADASTRO}\n",
    "    WHERE {CAMPO_CNPJ_CADASTRO} IS NOT NULL\n",
    "    \"\"\"\n",
    "    df_cadastro = spark.sql(query_cadastro)\n",
    "    total_cnpjs = df_cadastro.count()\n",
    "    print(f\"‚úì Carregados {total_cnpjs} CNPJs da tabela {TABELA_CADASTRO}\")\n",
    "\n",
    "# Criar view tempor√°ria\n",
    "df_cadastro.createOrReplaceTempView(\"cadastro_cnpj\")\n",
    "\n",
    "# Exibir amostra\n",
    "print(\"\\nAmostra de CNPJs:\")\n",
    "df_cadastro.limit(10).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc71eff-8614-4adf-aec9-a9e1b2eff84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 5: CRIAR VIEW DE NFe (OTIMIZADA + SKIP PER√çODO CORROMPIDO)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRIANDO VIEW DE NFe PROCESSADA (OTIMIZADA)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# REFRESH da tabela NFe primeiro\n",
    "print(\"Fazendo REFRESH da tabela nfe.nfe...\")\n",
    "try:\n",
    "    spark.sql(\"REFRESH TABLE nfe.nfe\")\n",
    "    print(\"‚úì REFRESH executado\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö† REFRESH falhou: {e}\")\n",
    "\n",
    "# Materializar os CNPJs em cache\n",
    "spark.sql(\"CACHE TABLE cadastro_cnpj\")\n",
    "cnpj_list = [row.cnpj for row in spark.sql(\"SELECT cnpj FROM cadastro_cnpj\").collect()]\n",
    "print(f\"CNPJs no cadastro: {len(cnpj_list)}\")\n",
    "\n",
    "# Criar string para usar no IN clause\n",
    "cnpj_in_clause = \"', '\".join(cnpj_list)\n",
    "\n",
    "# ‚ö†Ô∏è AJUSTE CR√çTICO: Pular per√≠odos corrompidos\n",
    "# Se 202001 est√° corrompido, come√ßar de 202002\n",
    "PERIODO_INICIO_AJUSTADO = 202101  # Come√ßar de Janeiro/2021 ao inv√©s de 2020\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è ATEN√á√ÉO: Pulando per√≠odo 2020 devido a arquivos corrompidos\")\n",
    "print(f\"Per√≠odo ajustado: {PERIODO_INICIO_AJUSTADO} at√© {PERIODO_FIM}\")\n",
    "\n",
    "query_nfe_view = f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_nfe_processada AS\n",
    "SELECT \n",
    "    -- Identifica√ß√£o\n",
    "    a.chave AS chave_nfe,\n",
    "    (a.ano_emissao * 100 + a.mes_emissao) AS periodo_ref,\n",
    "    CONCAT(LPAD(a.mes_emissao, 2, '0'), '/', a.ano_emissao) AS periodo_ref_formatado,\n",
    "    a.dhemi_orig AS data_hora_emissao,\n",
    "    \n",
    "    -- Emitente (limpeza feita uma vez)\n",
    "    cnpj_emit AS cnpj_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.xnome AS razao_social_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.xfant AS nome_fantasia_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.ie AS ie_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.crt AS crt_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.enderemit.uf AS uf_emitente,\n",
    "    a.procnfe.nfe.infnfe.emit.enderemit.xmun AS municipio_emitente,\n",
    "    \n",
    "    -- Destinat√°rio (limpeza feita uma vez)\n",
    "    cnpj_dest AS cnpj_destinatario,\n",
    "    a.procnfe.nfe.infnfe.dest.xnome AS razao_social_destinatario,\n",
    "    a.procnfe.nfe.infnfe.dest.ie AS ie_destinatario,\n",
    "    a.procnfe.nfe.infnfe.dest.indiedest AS indicador_ie_destinatario,\n",
    "    a.procnfe.nfe.infnfe.dest.enderdest.uf AS uf_destinatario,\n",
    "    a.procnfe.nfe.infnfe.dest.enderdest.xmun AS municipio_destinatario,\n",
    "    \n",
    "    -- Opera√ß√£o\n",
    "    a.procnfe.nfe.infnfe.ide.natop AS natureza_operacao,\n",
    "    a.procnfe.nfe.infnfe.ide.tpnf AS tipo_nf,\n",
    "    CASE \n",
    "        WHEN a.procnfe.nfe.infnfe.ide.tpnf = 0 THEN 'Entrada'\n",
    "        WHEN a.procnfe.nfe.infnfe.ide.tpnf = 1 THEN 'Saida'\n",
    "        ELSE 'Indefinido'\n",
    "    END AS entrada_saida,\n",
    "    CASE \n",
    "        WHEN a.procnfe.nfe.infnfe.ide.indfinal = 1 THEN 'Consumidor final'\n",
    "        ELSE 'Normal'\n",
    "    END AS tipo_consumidor,\n",
    "    \n",
    "    -- Itens\n",
    "    b._nitem AS numero_item,\n",
    "    b.prod.cprod AS codigo_produto,\n",
    "    b.prod.xprod AS descricao_produto,\n",
    "    b.prod.ncm AS ncm,\n",
    "    b.prod.cfop AS cfop,\n",
    "    \n",
    "    -- Valores\n",
    "    CAST(COALESCE(b.prod.vprod, 0) AS DECIMAL(15,2)) AS valor_produto,\n",
    "    CAST(COALESCE(b.prod.vfrete, 0) AS DECIMAL(15,2)) AS valor_frete,\n",
    "    CAST(COALESCE(b.prod.vseg, 0) AS DECIMAL(15,2)) AS valor_seguro,\n",
    "    CAST(COALESCE(b.prod.vdesc, 0) AS DECIMAL(15,2)) AS valor_desconto,\n",
    "    CAST(COALESCE(b.prod.voutro, 0) AS DECIMAL(15,2)) AS valor_outras_despesas,\n",
    "    \n",
    "    -- ICMS\n",
    "    b.imposto.icms.resumo.cst AS cst_icms,\n",
    "    CAST(COALESCE(b.imposto.icms.resumo.vbc, 0) AS DECIMAL(15,2)) AS bc_icms,\n",
    "    CAST(COALESCE(b.imposto.icms.resumo.picms, 0) AS DECIMAL(7,4)) AS aliquota_icms,\n",
    "    CAST(COALESCE(b.imposto.icms.resumo.vicms, 0) AS DECIMAL(15,2)) AS valor_icms,\n",
    "    CAST(COALESCE(b.imposto.icms.resumo.vcredicmssn, 0) AS DECIMAL(15,2)) AS valor_credito_sn,\n",
    "    \n",
    "    -- Totais NFe\n",
    "    CAST(COALESCE(a.procnfe.nfe.infnfe.total.icmstot.vnf, 0) AS DECIMAL(15,2)) AS total_nfe,\n",
    "    \n",
    "    -- Flags cadastro\n",
    "    IF(cnpj_emit IN ('{cnpj_in_clause}'), 1, 0) AS emitente_no_cadastro,\n",
    "    IF(cnpj_dest IN ('{cnpj_in_clause}'), 1, 0) AS destinatario_no_cadastro\n",
    "\n",
    "FROM (\n",
    "    SELECT \n",
    "        *,\n",
    "        REGEXP_REPLACE(TRIM(CAST(procnfe.nfe.infnfe.emit.cnpj AS STRING)), '[^0-9]', '') AS cnpj_emit,\n",
    "        REGEXP_REPLACE(TRIM(CAST(procnfe.nfe.infnfe.dest.cnpj AS STRING)), '[^0-9]', '') AS cnpj_dest\n",
    "    FROM nfe.nfe\n",
    "    WHERE situacao = 1\n",
    "      AND (ano_emissao * 100 + mes_emissao) >= {PERIODO_INICIO_AJUSTADO}\n",
    "      AND (ano_emissao * 100 + mes_emissao) <= {PERIODO_FIM}\n",
    ") a\n",
    "LATERAL VIEW EXPLODE(a.procnfe.nfe.infnfe.det) exploded_table AS b\n",
    "WHERE cnpj_emit IN ('{cnpj_in_clause}')\n",
    "   OR cnpj_dest IN ('{cnpj_in_clause}')\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_nfe_view)\n",
    "    print(\"‚úì View criada\")\n",
    "    \n",
    "    # Verificar SEM executar count completo (muito pesado)\n",
    "    print(\"\\n‚úì View NFe criada com sucesso\")\n",
    "    print(f\"Per√≠odo: {PERIODO_INICIO_AJUSTADO} at√© {PERIODO_FIM}\")\n",
    "    \n",
    "    # Amostra para verificar\n",
    "    print(\"\\nAmostra dos dados (5 registros):\")\n",
    "    spark.sql(\"SELECT periodo_ref, cnpj_emitente, cnpj_destinatario, entrada_saida, valor_produto FROM vw_nfe_processada LIMIT 5\").show(truncate=False)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erro: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n‚úì Pronto para pr√≥ximas etapas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c6c35c-c809-489f-b57f-2e1eaf9069b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 6: INTEGRAR CFOP (Execute ap√≥s a c√©lula 5 terminar)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTEGRANDO INFORMA√á√ïES DE CFOP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_cfop_view = \"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_nfe_com_cfop AS\n",
    "SELECT \n",
    "    nfe.*,\n",
    "    cfop.conta,\n",
    "    cfop.descricaocfop,\n",
    "    cfop.indcom,\n",
    "    cfop.movimento\n",
    "FROM vw_nfe_processada nfe\n",
    "LEFT JOIN niat.tabela_cfop cfop \n",
    "    ON nfe.cfop = cfop.cfop\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query_cfop_view)\n",
    "print(\"‚úì View vw_nfe_com_cfop criada\")\n",
    "\n",
    "# Verificar\n",
    "total = spark.sql(\"SELECT COUNT(*) as total FROM vw_nfe_com_cfop\").collect()[0]['total']\n",
    "print(f\"‚úì Total: {total:,} registros\")\n",
    "\n",
    "# Top CFOPs\n",
    "print(\"\\nTop 10 CFOPs:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        cfop,\n",
    "        descricaocfop,\n",
    "        conta,\n",
    "        entrada_saida,\n",
    "        COUNT(*) as qtde,\n",
    "        ROUND(SUM(valor_produto), 2) as vl_total\n",
    "    FROM vw_nfe_com_cfop\n",
    "    GROUP BY cfop, descricaocfop, conta, entrada_saida\n",
    "    ORDER BY qtde DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d783072-7f84-43f0-b8bb-e4901db6372a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 6: INTEGRAR CFOP (CORRIGIDA)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INTEGRANDO INFORMA√á√ïES DE CFOP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Primeiro, carregar a tabela CFOP para mem√≥ria\n",
    "try:\n",
    "    print(\"Carregando tabela CFOP...\")\n",
    "    df_cfop = spark.sql(\"\"\"\n",
    "        SELECT \n",
    "            cfop,\n",
    "            conta,\n",
    "            descricaocfop,\n",
    "            indcom,\n",
    "            movimento,\n",
    "            especial,\n",
    "            local,\n",
    "            mercenergtel\n",
    "        FROM niat.tabela_cfop\n",
    "    \"\"\")\n",
    "    \n",
    "    # Criar view tempor√°ria\n",
    "    df_cfop.createOrReplaceTempView(\"temp_cfop\")\n",
    "    total_cfops = df_cfop.count()\n",
    "    print(f\"‚úì Tabela CFOP carregada: {total_cfops} registros\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erro ao carregar tabela CFOP: {e}\")\n",
    "    print(\"\\nCriando tabela CFOP b√°sica manualmente...\")\n",
    "    \n",
    "    # Se n√£o conseguir acessar, criar uma b√°sica\n",
    "    cfop_data = [\n",
    "        (1101, 0, \"Compra para industrializa√ß√£o\", \"Industrializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (1102, 0, \"Compra para comercializa√ß√£o\", \"Comercializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (5101, 1, \"Venda de produ√ß√£o do estabelecimento\", \"Industrializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (5102, 1, \"Venda de mercadoria adquirida\", \"Comercializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (5403, 1, \"Venda de mercadoria em opera√ß√£o com n√£o contribuinte\", \"Comercializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (6101, 1, \"Venda de produ√ß√£o interestadual\", \"Industrializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "        (6102, 1, \"Venda de mercadoria interestadual\", \"Comercializa√ß√£o\", \"Opera√ß√£o\"),\n",
    "    ]\n",
    "    \n",
    "    from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "    schema = StructType([\n",
    "        StructField(\"cfop\", IntegerType(), True),\n",
    "        StructField(\"conta\", IntegerType(), True),\n",
    "        StructField(\"descricaocfop\", StringType(), True),\n",
    "        StructField(\"indcom\", StringType(), True),\n",
    "        StructField(\"movimento\", StringType(), True),\n",
    "    ])\n",
    "    \n",
    "    df_cfop = spark.createDataFrame(cfop_data, schema)\n",
    "    df_cfop.createOrReplaceTempView(\"temp_cfop\")\n",
    "    print(\"‚úì Tabela CFOP b√°sica criada\")\n",
    "\n",
    "# Agora fazer o join com a view tempor√°ria\n",
    "query_cfop_view = \"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_nfe_com_cfop AS\n",
    "SELECT \n",
    "    nfe.*,\n",
    "    cfop.conta,\n",
    "    cfop.descricaocfop,\n",
    "    cfop.indcom,\n",
    "    cfop.movimento\n",
    "FROM vw_nfe_processada nfe\n",
    "LEFT JOIN temp_cfop cfop \n",
    "    ON nfe.cfop = cfop.cfop\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query_cfop_view)\n",
    "print(\"‚úì View vw_nfe_com_cfop criada\")\n",
    "\n",
    "# Verificar\n",
    "total = spark.sql(\"SELECT COUNT(*) as total FROM vw_nfe_com_cfop\").collect()[0]['total']\n",
    "print(f\"‚úì Total: {total:,} registros\")\n",
    "\n",
    "# Verificar quantos CFOPs n√£o foram encontrados\n",
    "cfops_sem_desc = spark.sql(\"\"\"\n",
    "    SELECT COUNT(*) as total \n",
    "    FROM vw_nfe_com_cfop \n",
    "    WHERE descricaocfop IS NULL\n",
    "\"\"\").collect()[0]['total']\n",
    "\n",
    "if cfops_sem_desc > 0:\n",
    "    print(f\"‚ö† {cfops_sem_desc:,} registros sem descri√ß√£o de CFOP\")\n",
    "\n",
    "# Top CFOPs\n",
    "print(\"\\nTop 10 CFOPs:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        cfop,\n",
    "        descricaocfop,\n",
    "        conta,\n",
    "        entrada_saida,\n",
    "        COUNT(*) as qtde,\n",
    "        ROUND(SUM(valor_produto), 2) as vl_total\n",
    "    FROM vw_nfe_com_cfop\n",
    "    GROUP BY cfop, descricaocfop, conta, entrada_saida\n",
    "    ORDER BY qtde DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0853f976-703d-4b6c-9613-a17955245790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 7: CALCULAR ICMS\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CALCULANDO ICMS - D√âBITOS E CR√âDITOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_icms = \"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_nfe_com_icms AS\n",
    "SELECT \n",
    "    *,\n",
    "    -- BC total do item\n",
    "    (valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto) AS bc_total_item,\n",
    "    \n",
    "    -- D√âBITO (Sa√≠da)\n",
    "    CASE \n",
    "        WHEN entrada_saida = 'Saida' AND conta = 1 THEN\n",
    "            CASE\n",
    "                WHEN valor_icms > 0 THEN valor_icms\n",
    "                WHEN bc_icms > 0 AND aliquota_icms > 0 THEN bc_icms * (aliquota_icms / 100)\n",
    "                WHEN tipo_consumidor = 'Consumidor final' THEN \n",
    "                    (valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto) * 0.17\n",
    "                WHEN uf_destinatario IN ('MG', 'PR', 'RJ', 'RS', 'SP') AND uf_destinatario != uf_emitente THEN\n",
    "                    (valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto) * 0.12\n",
    "                WHEN uf_destinatario != uf_emitente THEN\n",
    "                    (valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto) * 0.07\n",
    "                ELSE \n",
    "                    (valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto) * 0.12\n",
    "            END\n",
    "        ELSE 0\n",
    "    END AS vl_icms_debito,\n",
    "    \n",
    "    CASE \n",
    "        WHEN entrada_saida = 'Saida' AND conta = 1 THEN\n",
    "            COALESCE(bc_icms, valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto)\n",
    "        ELSE 0\n",
    "    END AS bc_icms_debito,\n",
    "    \n",
    "    -- CR√âDITO (Entrada)\n",
    "    CASE \n",
    "        WHEN entrada_saida = 'Entrada' AND conta = -1 \n",
    "             AND cst_icms NOT IN ('10', '15', '30', '40', '41', '53', '60', '61', '70', '102', '202', '203', '300', '500') THEN\n",
    "            CASE\n",
    "                WHEN valor_icms > 0 THEN valor_icms\n",
    "                WHEN valor_credito_sn > 0 THEN valor_credito_sn\n",
    "                ELSE 0\n",
    "            END\n",
    "        ELSE 0\n",
    "    END AS vl_icms_credito,\n",
    "    \n",
    "    CASE \n",
    "        WHEN entrada_saida = 'Entrada' AND conta = -1 THEN\n",
    "            COALESCE(bc_icms, valor_produto + valor_frete + valor_seguro + valor_outras_despesas - valor_desconto)\n",
    "        ELSE 0\n",
    "    END AS bc_icms_credito\n",
    "\n",
    "FROM vw_nfe_com_cfop\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query_icms)\n",
    "print(\"‚úì View vw_nfe_com_icms criada\")\n",
    "\n",
    "# Resumo\n",
    "print(\"\\nüìä RESUMO ICMS:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        entrada_saida,\n",
    "        COUNT(*) as qtde_itens,\n",
    "        ROUND(SUM(bc_icms_debito), 2) as bc_debito,\n",
    "        ROUND(SUM(vl_icms_debito), 2) as vl_debito,\n",
    "        ROUND(SUM(bc_icms_credito), 2) as bc_credito,\n",
    "        ROUND(SUM(vl_icms_credito), 2) as vl_credito\n",
    "    FROM vw_nfe_com_icms\n",
    "    GROUP BY entrada_saida\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0166b7-58ce-4a8b-a5e7-9bac3e2bbd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 8: AN√ÅLISE POR ENTRADA/SA√çDA E EMITENTE/DESTINAT√ÅRIO\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEPARANDO: ENTRADA vs SA√çDA | EMITENTE vs DESTINAT√ÅRIO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ENTRADA - DESTINAT√ÅRIO (empresa do cadastro recebeu mercadoria)\n",
    "df_entrada_dest = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM vw_nfe_com_icms\n",
    "    WHERE entrada_saida = 'Entrada'\n",
    "      AND destinatario_no_cadastro = 1\n",
    "\"\"\")\n",
    "df_entrada_dest.createOrReplaceTempView(\"vw_entrada_destinatario\")\n",
    "total_ed = df_entrada_dest.count()\n",
    "print(f\"‚úì Entrada Destinat√°rio: {total_ed:,} registros\")\n",
    "\n",
    "# ENTRADA - EMITENTE (empresa do cadastro emitiu nota de devolu√ß√£o/retorno)\n",
    "df_entrada_emit = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM vw_nfe_com_icms\n",
    "    WHERE entrada_saida = 'Entrada'\n",
    "      AND emitente_no_cadastro = 1\n",
    "\"\"\")\n",
    "df_entrada_emit.createOrReplaceTempView(\"vw_entrada_emitente\")\n",
    "total_ee = df_entrada_emit.count()\n",
    "print(f\"‚úì Entrada Emitente: {total_ee:,} registros\")\n",
    "\n",
    "# SA√çDA - EMITENTE (empresa do cadastro vendeu)\n",
    "df_saida_emit = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM vw_nfe_com_icms\n",
    "    WHERE entrada_saida = 'Saida'\n",
    "      AND emitente_no_cadastro = 1\n",
    "\"\"\")\n",
    "df_saida_emit.createOrReplaceTempView(\"vw_saida_emitente\")\n",
    "total_se = df_saida_emit.count()\n",
    "print(f\"‚úì Sa√≠da Emitente: {total_se:,} registros\")\n",
    "\n",
    "# SA√çDA - DESTINAT√ÅRIO (empresa do cadastro recebeu venda de terceiro)\n",
    "df_saida_dest = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM vw_nfe_com_icms\n",
    "    WHERE entrada_saida = 'Saida'\n",
    "      AND destinatario_no_cadastro = 1\n",
    "\"\"\")\n",
    "df_saida_dest.createOrReplaceTempView(\"vw_saida_destinatario\")\n",
    "total_sd = df_saida_dest.count()\n",
    "print(f\"‚úì Sa√≠da Destinat√°rio: {total_sd:,} registros\")\n",
    "\n",
    "print(f\"\\n‚úì Total geral: {total_ed + total_ee + total_se + total_sd:,} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab4ae42-feb7-441d-a528-5ac17b13c738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 9: PROCESSAR CTe (CORRIGIDA - ESTRUTURA ICMS)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESSANDO CTe - CR√âDITO DE FRETE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_cte = f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_cte_processada AS\n",
    "SELECT \n",
    "    -- Identifica√ß√£o\n",
    "    a.chave AS chave_cte,\n",
    "    a.ano_emissao AS ano_emissao,\n",
    "    \n",
    "    -- Per√≠odo\n",
    "    CONCAT(\n",
    "        LPAD(MONTH(a.proccte.cte.infcte.ide.dhemi), 2, '0'), \n",
    "        '/', \n",
    "        YEAR(a.proccte.cte.infcte.ide.dhemi)\n",
    "    ) AS periodo_ref,\n",
    "    \n",
    "    (YEAR(a.proccte.cte.infcte.ide.dhemi) * 100 + MONTH(a.proccte.cte.infcte.ide.dhemi)) AS periodo_ref_num,\n",
    "    \n",
    "    a.proccte.cte.infcte.ide.dhemi AS data_hora_emissao,\n",
    "    \n",
    "    -- Tomador (quem paga o frete)\n",
    "    REGEXP_REPLACE(\n",
    "        TRIM(CAST(a.proccte.cte.infcte.ide.toma4.cnpj AS STRING)), \n",
    "        '[^0-9]', ''\n",
    "    ) AS cnpj_tomador,\n",
    "    \n",
    "    a.proccte.cte.infcte.ide.toma4.xnome AS nome_tomador,\n",
    "    a.proccte.cte.infcte.ide.toma4.toma AS indicador_tomador,\n",
    "    \n",
    "    -- Remetente\n",
    "    REGEXP_REPLACE(\n",
    "        TRIM(CAST(a.proccte.cte.infcte.rem.cnpj AS STRING)), \n",
    "        '[^0-9]', ''\n",
    "    ) AS cnpj_remetente,\n",
    "    \n",
    "    a.proccte.cte.infcte.rem.xnome AS nome_remetente,\n",
    "    \n",
    "    -- Destinat√°rio\n",
    "    REGEXP_REPLACE(\n",
    "        TRIM(CAST(a.proccte.cte.infcte.dest.cnpj AS STRING)), \n",
    "        '[^0-9]', ''\n",
    "    ) AS cnpj_destinatario,\n",
    "    \n",
    "    a.proccte.cte.infcte.dest.xnome AS nome_destinatario,\n",
    "    \n",
    "    -- Emitente (transportadora)\n",
    "    REGEXP_REPLACE(\n",
    "        TRIM(CAST(a.proccte.cte.infcte.emit.cnpj AS STRING)), \n",
    "        '[^0-9]', ''\n",
    "    ) AS cnpj_emitente,\n",
    "    \n",
    "    a.proccte.cte.infcte.emit.xnome AS nome_emitente,\n",
    "    a.proccte.cte.infcte.emit.ie AS ie_emitente,\n",
    "    \n",
    "    -- CFOP e Natureza\n",
    "    a.proccte.cte.infcte.ide.cfop AS cfop,\n",
    "    a.proccte.cte.infcte.ide.natop AS natureza_operacao,\n",
    "    a.proccte.cte.infcte.ide.modal AS modal,\n",
    "    a.proccte.cte.infcte.ide.tpserv AS tipo_servico,\n",
    "    \n",
    "    -- Valores\n",
    "    CAST(COALESCE(a.proccte.cte.infcte.vprest.vtprest, 0) AS DECIMAL(15,2)) AS valor_total_servico,\n",
    "    \n",
    "    -- ICMS - Estrutura CORRETA baseada no describe\n",
    "    CAST(COALESCE(\n",
    "        a.proccte.cte.infcte.imp.icms.icms00.vicms,\n",
    "        a.proccte.cte.infcte.imp.icms.icms20.vicms,\n",
    "        a.proccte.cte.infcte.imp.icms.icms60.vcred,\n",
    "        a.proccte.cte.infcte.imp.icms.icms90.vcred,\n",
    "        a.proccte.cte.infcte.imp.icms.cst00.vicms,\n",
    "        a.proccte.cte.infcte.imp.icms.cst20.vicms,\n",
    "        a.proccte.cte.infcte.imp.icms.cst80.vcred,\n",
    "        a.proccte.cte.infcte.imp.icms.cst90.vcred,\n",
    "        0\n",
    "    ) AS DECIMAL(15,2)) AS valor_icms,\n",
    "    \n",
    "    CAST(COALESCE(\n",
    "        a.proccte.cte.infcte.imp.icms.icms00.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.icms20.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.icms90.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.cst00.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.cst20.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.cst80.vbc,\n",
    "        a.proccte.cte.infcte.imp.icms.cst90.vbc,\n",
    "        0\n",
    "    ) AS DECIMAL(15,2)) AS bc_icms,\n",
    "    \n",
    "    -- CST\n",
    "    COALESCE(\n",
    "        a.proccte.cte.infcte.imp.icms.icms00.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.icms20.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.icms45.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.icms60.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.icms90.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.icmssn.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.cst00.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.cst20.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.cst45.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.cst80.cst,\n",
    "        a.proccte.cte.infcte.imp.icms.cst90.cst\n",
    "    ) AS cst_icms\n",
    "\n",
    "FROM cte.cte a\n",
    "WHERE a.situacao = 1\n",
    "  AND a.ano_emissao >= {PERIODO_INICIO // 100}\n",
    "  AND a.ano_emissao <= {PERIODO_FIM // 100}\n",
    "  AND a.proccte.cte.infcte.ide.toma4.cnpj IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_cte)\n",
    "    print(\"‚úì View vw_cte_processada criada\")\n",
    "    \n",
    "    # Filtrar CTe relevantes\n",
    "    query_cte_filtrado = f\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY VIEW vw_cte_filtrado AS\n",
    "    SELECT \n",
    "        *,\n",
    "        IF(cnpj_tomador IN ('{cnpj_in_clause}'), 1, 0) AS tomador_no_cadastro,\n",
    "        IF(cnpj_destinatario IN ('{cnpj_in_clause}'), 1, 0) AS destinatario_no_cadastro,\n",
    "        IF(cnpj_remetente IN ('{cnpj_in_clause}'), 1, 0) AS remetente_no_cadastro\n",
    "    FROM vw_cte_processada\n",
    "    WHERE periodo_ref_num >= {PERIODO_INICIO}\n",
    "      AND periodo_ref_num <= {PERIODO_FIM}\n",
    "      AND (\n",
    "          cnpj_tomador IN ('{cnpj_in_clause}')\n",
    "          OR cnpj_destinatario IN ('{cnpj_in_clause}')\n",
    "          OR cnpj_remetente IN ('{cnpj_in_clause}')\n",
    "      )\n",
    "    \"\"\"\n",
    "    \n",
    "    spark.sql(query_cte_filtrado)\n",
    "    total_cte = spark.sql(\"SELECT COUNT(*) as total FROM vw_cte_filtrado\").collect()[0]['total']\n",
    "    print(f\"‚úì CTe filtrados: {total_cte:,} registros\")\n",
    "    \n",
    "    if total_cte > 0:\n",
    "        # Resumo por per√≠odo\n",
    "        print(\"\\nResumo CTe por per√≠odo:\")\n",
    "        spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                periodo_ref,\n",
    "                COUNT(*) as qtde_cte,\n",
    "                ROUND(SUM(valor_total_servico), 2) as vl_total_servico,\n",
    "                ROUND(SUM(valor_icms), 2) as vl_icms_credito\n",
    "            FROM vw_cte_filtrado\n",
    "            GROUP BY periodo_ref\n",
    "            ORDER BY periodo_ref\n",
    "        \"\"\").show(20, truncate=False)\n",
    "        \n",
    "        # Resumo por modal\n",
    "        print(\"\\nResumo por Modal de Transporte:\")\n",
    "        spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                CASE \n",
    "                    WHEN modal = 1 THEN 'Rodovi√°rio'\n",
    "                    WHEN modal = 2 THEN 'A√©reo'\n",
    "                    WHEN modal = 3 THEN 'Aquavi√°rio'\n",
    "                    WHEN modal = 4 THEN 'Ferrovi√°rio'\n",
    "                    WHEN modal = 5 THEN 'Dutovi√°rio'\n",
    "                    WHEN modal = 6 THEN 'Multimodal'\n",
    "                    ELSE 'Outros'\n",
    "                END as modal_descricao,\n",
    "                COUNT(*) as qtde,\n",
    "                ROUND(SUM(valor_icms), 2) as vl_icms\n",
    "            FROM vw_cte_filtrado\n",
    "            GROUP BY modal\n",
    "            ORDER BY qtde DESC\n",
    "        \"\"\").show(truncate=False)\n",
    "        \n",
    "        # Principais transportadoras\n",
    "        print(\"\\nTop 10 Transportadoras:\")\n",
    "        spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                nome_emitente,\n",
    "                cnpj_emitente,\n",
    "                COUNT(*) as qtde_cte,\n",
    "                ROUND(SUM(valor_total_servico), 2) as vl_total,\n",
    "                ROUND(SUM(valor_icms), 2) as vl_icms\n",
    "            FROM vw_cte_filtrado\n",
    "            GROUP BY nome_emitente, cnpj_emitente\n",
    "            ORDER BY vl_total DESC\n",
    "            LIMIT 10\n",
    "        \"\"\").show(truncate=False)\n",
    "    else:\n",
    "        print(\"\\n‚ö† Nenhum CTe encontrado para os CNPJs do cadastro no per√≠odo\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erro ao processar CTe: {e}\")\n",
    "    print(\"\\n‚ö† Criando view CTe vazia para continuar processamento...\")\n",
    "    \n",
    "    # Criar view vazia\n",
    "    spark.sql(\"\"\"\n",
    "        CREATE OR REPLACE TEMPORARY VIEW vw_cte_filtrado AS\n",
    "        SELECT \n",
    "            CAST(NULL AS STRING) AS periodo_ref,\n",
    "            CAST(NULL AS INT) AS periodo_ref_num,\n",
    "            CAST(NULL AS STRING) AS cnpj_tomador,\n",
    "            CAST(0 AS DECIMAL(15,2)) AS valor_icms,\n",
    "            CAST(0 AS INT) AS tomador_no_cadastro\n",
    "        WHERE 1=0\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"‚úì View CTe vazia criada - processamento continuar√° sem dados de CTe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2350d0c-439f-4e40-8a18-1ca6dc4d8102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 10: CARREGAR PGDAS-D (Simples Nacional)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CARREGANDO DADOS PGDAS-D (SIMPLES NACIONAL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_pgdas = f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_pgdas_filtrado AS\n",
    "SELECT \n",
    "    REGEXP_REPLACE(TRIM(nu_cnpj), '[^0-9]', '') AS cnpj,\n",
    "    nu_per_ref AS periodo_ref,\n",
    "    CONCAT(LPAD(nu_per_ref % 100, 2, '0'), '/', CAST(nu_per_ref / 100 AS INT)) AS periodo_formatado,\n",
    "    CAST(COALESCE(vl_rec_bruta_estab, 0) AS DECIMAL(15,2)) AS receita_bruta,\n",
    "    CAST(COALESCE(vl_icms_sc, 0) AS DECIMAL(15,2)) AS icms_declarado_sc\n",
    "FROM usr_sat_ods.sna_pgdasd_estabelecimento_raw\n",
    "WHERE nu_per_ref >= {PERIODO_INICIO}\n",
    "  AND nu_per_ref <= {PERIODO_FIM}\n",
    "  AND REGEXP_REPLACE(TRIM(nu_cnpj), '[^0-9]', '') IN ('{cnpj_in_clause}')\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query_pgdas)\n",
    "total_pgdas = spark.sql(\"SELECT COUNT(*) as total FROM vw_pgdas_filtrado\").collect()[0]['total']\n",
    "print(f\"‚úì PGDAS-D carregado: {total_pgdas:,} registros\")\n",
    "\n",
    "# Mostrar amostra\n",
    "print(\"\\nAmostra PGDAS-D:\")\n",
    "spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM vw_pgdas_filtrado\n",
    "    ORDER BY periodo_ref DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffbdc5-d393-473c-a52c-106fa9da9fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 11: CONSOLIDAR NOTIFICA√á√ÉO (CORRIGIDA COM TRATAMENTO)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO NOTIFICA√á√ÉO - APURA√á√ÉO MENSAL DE ICMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_notificacao = \"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_notificacao AS\n",
    "WITH apuracao_saida AS (\n",
    "    SELECT \n",
    "        periodo_ref,\n",
    "        cnpj_emitente AS cnpj,\n",
    "        SUM(bc_icms_debito) AS bc_icms_saida,\n",
    "        SUM(vl_icms_debito) AS vl_icms_saida\n",
    "    FROM vw_saida_emitente\n",
    "    GROUP BY periodo_ref, cnpj_emitente\n",
    "),\n",
    "apuracao_entrada AS (\n",
    "    SELECT \n",
    "        periodo_ref,\n",
    "        cnpj_destinatario AS cnpj,\n",
    "        SUM(bc_icms_credito) AS bc_icms_entrada,\n",
    "        SUM(vl_icms_credito) AS vl_icms_entrada\n",
    "    FROM vw_entrada_destinatario\n",
    "    GROUP BY periodo_ref, cnpj_destinatario\n",
    "),\n",
    "apuracao_cte AS (\n",
    "    SELECT \n",
    "        periodo_ref_num AS periodo_ref,\n",
    "        cnpj_tomador AS cnpj,\n",
    "        SUM(valor_icms) AS vl_icms_cte\n",
    "    FROM vw_cte_filtrado\n",
    "    WHERE tomador_no_cadastro = 1\n",
    "    GROUP BY periodo_ref_num, cnpj_tomador\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) AS periodo,\n",
    "    COALESCE(s.cnpj, e.cnpj, c.cnpj, p.cnpj) AS cnpj,\n",
    "    CONCAT(\n",
    "        LPAD(CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) % 100 AS STRING), 2, '0'),\n",
    "        '/',\n",
    "        CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) / 100 AS STRING)\n",
    "    ) AS periodo_formatado,\n",
    "    \n",
    "    -- D√©bitos\n",
    "    ROUND(COALESCE(s.bc_icms_saida, 0), 2) AS bc_icms_saida,\n",
    "    ROUND(COALESCE(s.vl_icms_saida, 0), 2) AS vl_icms_saida,\n",
    "    \n",
    "    -- Cr√©ditos\n",
    "    ROUND(COALESCE(e.bc_icms_entrada, 0), 2) AS bc_icms_entrada,\n",
    "    ROUND(COALESCE(e.vl_icms_entrada, 0), 2) AS vl_icms_entrada,\n",
    "    ROUND(COALESCE(c.vl_icms_cte, 0), 2) AS vl_icms_cte,\n",
    "    \n",
    "    -- PGDAS-D\n",
    "    ROUND(COALESCE(p.receita_bruta, 0), 2) AS receita_bruta_declarada,\n",
    "    ROUND(COALESCE(p.icms_declarado_sc, 0), 2) AS icms_declarado,\n",
    "    \n",
    "    -- C√°lculos\n",
    "    ROUND(COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0), 2) AS receita_nao_declarada,\n",
    "    ROUND((COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0)) * 0.17, 2) AS vl_icms_receita_omitida,\n",
    "    \n",
    "    -- ICMS DEVIDO\n",
    "    ROUND(\n",
    "        COALESCE(s.vl_icms_saida, 0) +\n",
    "        ((COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0)) * 0.17) -\n",
    "        COALESCE(e.vl_icms_entrada, 0) -\n",
    "        COALESCE(c.vl_icms_cte, 0) -\n",
    "        COALESCE(p.icms_declarado_sc, 0),\n",
    "        2\n",
    "    ) AS vl_icms_devido,\n",
    "    \n",
    "    -- Vencimento (dia 10 do m√™s seguinte)\n",
    "    DATE_FORMAT(\n",
    "        ADD_MONTHS(\n",
    "            CONCAT(\n",
    "                CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) / 100 AS INT), '-',\n",
    "                LPAD(CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) % 100 AS INT), 2, '0'), '-01'\n",
    "            ),\n",
    "            1\n",
    "        ),\n",
    "        'yyyy-MM-10'\n",
    "    ) AS data_vencimento\n",
    "\n",
    "FROM apuracao_saida s\n",
    "FULL OUTER JOIN apuracao_entrada e \n",
    "    ON s.periodo_ref = e.periodo_ref AND s.cnpj = e.cnpj\n",
    "FULL OUTER JOIN apuracao_cte c \n",
    "    ON COALESCE(s.periodo_ref, e.periodo_ref) = c.periodo_ref \n",
    "    AND COALESCE(s.cnpj, e.cnpj) = c.cnpj\n",
    "FULL OUTER JOIN vw_pgdas_filtrado p \n",
    "    ON COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref) = p.periodo_ref\n",
    "    AND COALESCE(s.cnpj, e.cnpj, c.cnpj) = p.cnpj\n",
    "ORDER BY cnpj, periodo\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    spark.sql(query_notificacao)\n",
    "    print(\"‚úì View vw_notificacao criada\")\n",
    "    \n",
    "    # Materializar resultado para evitar reprocessamento\n",
    "    print(\"\\nMaterializando dados da notifica√ß√£o...\")\n",
    "    df_notificacao = spark.sql(\"SELECT * FROM vw_notificacao ORDER BY cnpj, periodo\")\n",
    "    df_notificacao.cache()  # Cachear para evitar recalcular\n",
    "    \n",
    "    total_periodos = df_notificacao.count()\n",
    "    print(f\"‚úì Total de per√≠odos apurados: {total_periodos}\")\n",
    "    \n",
    "    if total_periodos > 0:\n",
    "        print(\"\\nAPURA√á√ÉO MENSAL DE ICMS (primeiros 20 per√≠odos):\")\n",
    "        df_notificacao.show(20, truncate=False)\n",
    "        \n",
    "        # Converter para Pandas (s√≥ depois de cachear)\n",
    "        print(\"\\nConvertendo para Pandas...\")\n",
    "        df_notif_pandas = df_notificacao.toPandas()\n",
    "        \n",
    "        # Estat√≠sticas gerais\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"ESTAT√çSTICAS CONSOLIDADAS\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"Total ICMS Devido: R$ {df_notif_pandas['vl_icms_devido'].sum():,.2f}\")\n",
    "        print(f\"Total D√©bitos (Sa√≠da): R$ {df_notif_pandas['vl_icms_saida'].sum():,.2f}\")\n",
    "        print(f\"Total Cr√©ditos (Entrada): R$ {df_notif_pandas['vl_icms_entrada'].sum():,.2f}\")\n",
    "        print(f\"Total Cr√©ditos (CTe): R$ {df_notif_pandas['vl_icms_cte'].sum():,.2f}\")\n",
    "        print(f\"Total ICMS Declarado: R$ {df_notif_pandas['icms_declarado'].sum():,.2f}\")\n",
    "        print(f\"Receita N√£o Declarada: R$ {df_notif_pandas['receita_nao_declarada'].sum():,.2f}\")\n",
    "        print(f\"ICMS sobre Receita Omitida: R$ {df_notif_pandas['vl_icms_receita_omitida'].sum():,.2f}\")\n",
    "        \n",
    "        # Resumo por CNPJ\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"RESUMO POR CNPJ\")\n",
    "        print(\"=\" * 80)\n",
    "        resumo_cnpj = df_notif_pandas.groupby('cnpj').agg({\n",
    "            'periodo': 'count',\n",
    "            'vl_icms_saida': 'sum',\n",
    "            'vl_icms_entrada': 'sum',\n",
    "            'vl_icms_cte': 'sum',\n",
    "            'icms_declarado': 'sum',\n",
    "            'vl_icms_devido': 'sum',\n",
    "            'receita_nao_declarada': 'sum'\n",
    "        }).round(2)\n",
    "        resumo_cnpj.columns = ['Qtde_Per√≠odos', 'Total_D√©bitos', 'Total_Cr√©d_Entrada', \n",
    "                                'Total_Cr√©d_CTe', 'Total_Declarado', 'Total_Devido', 'Rec_Omitida']\n",
    "        print(resumo_cnpj)\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n‚ö† Nenhum per√≠odo com dados para apura√ß√£o\")\n",
    "        df_notif_pandas = pd.DataFrame()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\n‚úó Erro ao gerar notifica√ß√£o: {e}\")\n",
    "    print(\"\\nTentando com per√≠odo mais restrito (√∫ltimos 12 meses)...\")\n",
    "    \n",
    "    # Recalcular per√≠odo mais recente\n",
    "    periodo_fim_reduzido = PERIODO_FIM\n",
    "    periodo_inicio_reduzido = (PERIODO_FIM // 100 - 1) * 100 + (PERIODO_FIM % 100)\n",
    "    \n",
    "    print(f\"Per√≠odo ajustado: {periodo_inicio_reduzido} a {periodo_fim_reduzido}\")\n",
    "    \n",
    "    # Voc√™ pode tentar reprocessar com per√≠odo menor\n",
    "    df_notif_pandas = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a009040-c750-45c2-88db-f88544e18bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 11: CONSOLIDAR NOTIFICA√á√ÉO (CORRIGIDA)\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GERANDO NOTIFICA√á√ÉO - APURA√á√ÉO MENSAL DE ICMS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_notificacao = \"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW vw_notificacao AS\n",
    "WITH apuracao_saida AS (\n",
    "    SELECT \n",
    "        periodo_ref,\n",
    "        cnpj_emitente AS cnpj,\n",
    "        SUM(bc_icms_debito) AS bc_icms_saida,\n",
    "        SUM(vl_icms_debito) AS vl_icms_saida\n",
    "    FROM vw_saida_emitente\n",
    "    GROUP BY periodo_ref, cnpj_emitente\n",
    "),\n",
    "apuracao_entrada AS (\n",
    "    SELECT \n",
    "        periodo_ref,\n",
    "        cnpj_destinatario AS cnpj,\n",
    "        SUM(bc_icms_credito) AS bc_icms_entrada,\n",
    "        SUM(vl_icms_credito) AS vl_icms_entrada\n",
    "    FROM vw_entrada_destinatario\n",
    "    GROUP BY periodo_ref, cnpj_destinatario\n",
    "),\n",
    "apuracao_cte AS (\n",
    "    SELECT \n",
    "        periodo_ref_num AS periodo_ref,\n",
    "        cnpj_tomador AS cnpj,\n",
    "        SUM(valor_icms) AS vl_icms_cte\n",
    "    FROM vw_cte_filtrado\n",
    "    WHERE tomador_no_cadastro = 1\n",
    "    GROUP BY periodo_ref_num, cnpj_tomador\n",
    ")\n",
    "SELECT \n",
    "    COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) AS periodo,\n",
    "    COALESCE(s.cnpj, e.cnpj, c.cnpj, p.cnpj) AS cnpj,\n",
    "    CONCAT(\n",
    "        LPAD(CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) % 100 AS STRING), 2, '0'),\n",
    "        '/',\n",
    "        CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) / 100 AS STRING)\n",
    "    ) AS periodo_formatado,\n",
    "    \n",
    "    -- D√©bitos\n",
    "    ROUND(COALESCE(s.bc_icms_saida, 0), 2) AS bc_icms_saida,\n",
    "    ROUND(COALESCE(s.vl_icms_saida, 0), 2) AS vl_icms_saida,\n",
    "    \n",
    "    -- Cr√©ditos\n",
    "    ROUND(COALESCE(e.bc_icms_entrada, 0), 2) AS bc_icms_entrada,\n",
    "    ROUND(COALESCE(e.vl_icms_entrada, 0), 2) AS vl_icms_entrada,\n",
    "    ROUND(COALESCE(c.vl_icms_cte, 0), 2) AS vl_icms_cte,\n",
    "    \n",
    "    -- PGDAS-D\n",
    "    ROUND(COALESCE(p.receita_bruta, 0), 2) AS receita_bruta_declarada,\n",
    "    ROUND(COALESCE(p.icms_declarado_sc, 0), 2) AS icms_declarado,\n",
    "    \n",
    "    -- C√°lculos\n",
    "    ROUND(COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0), 2) AS receita_nao_declarada,\n",
    "    ROUND((COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0)) * 0.17, 2) AS vl_icms_receita_omitida,\n",
    "    \n",
    "    -- ICMS DEVIDO\n",
    "    ROUND(\n",
    "        COALESCE(s.vl_icms_saida, 0) +\n",
    "        ((COALESCE(s.bc_icms_saida, 0) - COALESCE(p.receita_bruta, 0)) * 0.17) -\n",
    "        COALESCE(e.vl_icms_entrada, 0) -\n",
    "        COALESCE(c.vl_icms_cte, 0) -\n",
    "        COALESCE(p.icms_declarado_sc, 0),\n",
    "        2\n",
    "    ) AS vl_icms_devido,\n",
    "    \n",
    "    -- Vencimento (dia 10 do m√™s seguinte)\n",
    "    DATE_FORMAT(\n",
    "        ADD_MONTHS(\n",
    "            CONCAT(\n",
    "                CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) / 100 AS INT), '-',\n",
    "                LPAD(CAST(COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref, p.periodo_ref) % 100 AS INT), 2, '0'), '-01'\n",
    "            ),\n",
    "            1\n",
    "        ),\n",
    "        'yyyy-MM-10'\n",
    "    ) AS data_vencimento\n",
    "\n",
    "FROM apuracao_saida s\n",
    "FULL OUTER JOIN apuracao_entrada e \n",
    "    ON s.periodo_ref = e.periodo_ref AND s.cnpj = e.cnpj\n",
    "FULL OUTER JOIN apuracao_cte c \n",
    "    ON COALESCE(s.periodo_ref, e.periodo_ref) = c.periodo_ref \n",
    "    AND COALESCE(s.cnpj, e.cnpj) = c.cnpj\n",
    "FULL OUTER JOIN vw_pgdas_filtrado p \n",
    "    ON COALESCE(s.periodo_ref, e.periodo_ref, c.periodo_ref) = p.periodo_ref\n",
    "    AND COALESCE(s.cnpj, e.cnpj, c.cnpj) = p.cnpj\n",
    "ORDER BY cnpj, periodo\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query_notificacao)\n",
    "print(\"‚úì View vw_notificacao criada\")\n",
    "\n",
    "# Exibir resultado\n",
    "df_notificacao = spark.sql(\"SELECT * FROM vw_notificacao ORDER BY cnpj, periodo\")\n",
    "total_periodos = df_notificacao.count()\n",
    "print(f\"\\nTotal de per√≠odos apurados: {total_periodos}\")\n",
    "\n",
    "if total_periodos > 0:\n",
    "    print(\"\\nAPURA√á√ÉO MENSAL DE ICMS:\")\n",
    "    df_notificacao.show(50, truncate=False)\n",
    "    \n",
    "    # Converter para Pandas para an√°lises\n",
    "    df_notif_pandas = df_notificacao.toPandas()\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ESTAT√çSTICAS CONSOLIDADAS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"Total ICMS Devido: R$ {df_notif_pandas['vl_icms_devido'].sum():,.2f}\")\n",
    "    print(f\"Total D√©bitos (Sa√≠da): R$ {df_notif_pandas['vl_icms_saida'].sum():,.2f}\")\n",
    "    print(f\"Total Cr√©ditos (Entrada): R$ {df_notif_pandas['vl_icms_entrada'].sum():,.2f}\")\n",
    "    print(f\"Total Cr√©ditos (CTe): R$ {df_notif_pandas['vl_icms_cte'].sum():,.2f}\")\n",
    "    print(f\"Total ICMS Declarado: R$ {df_notif_pandas['icms_declarado'].sum():,.2f}\")\n",
    "    print(f\"Receita N√£o Declarada: R$ {df_notif_pandas['receita_nao_declarada'].sum():,.2f}\")\n",
    "    print(f\"ICMS sobre Receita Omitida: R$ {df_notif_pandas['vl_icms_receita_omitida'].sum():,.2f}\")\n",
    "    \n",
    "    # Resumo por CNPJ\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"RESUMO POR CNPJ\")\n",
    "    print(\"=\" * 80)\n",
    "    resumo_cnpj = df_notif_pandas.groupby('cnpj').agg({\n",
    "        'periodo': 'count',\n",
    "        'vl_icms_saida': 'sum',\n",
    "        'vl_icms_entrada': 'sum',\n",
    "        'vl_icms_cte': 'sum',\n",
    "        'icms_declarado': 'sum',\n",
    "        'vl_icms_devido': 'sum',\n",
    "        'receita_nao_declarada': 'sum'\n",
    "    }).round(2)\n",
    "    resumo_cnpj.columns = ['Qtde_Per√≠odos', 'Total_D√©bitos', 'Total_Cr√©d_Entrada', \n",
    "                            'Total_Cr√©d_CTe', 'Total_Declarado', 'Total_Devido', 'Rec_Omitida']\n",
    "    print(resumo_cnpj)\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ö† Nenhum per√≠odo com dados para apura√ß√£o\")\n",
    "    df_notif_pandas = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fabfcf-77ae-487e-b3ed-400a324888e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 12: VISUALIZA√á√ïES E AN√ÅLISES\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUALIZA√á√ïES E AN√ÅLISES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preparar dados\n",
    "df_plot = df_notif_pandas.copy()\n",
    "df_plot['periodo'] = df_plot['periodo'].astype(str)\n",
    "\n",
    "# Criar figura com m√∫ltiplos gr√°ficos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "fig.suptitle('AN√ÅLISE FISCAL - ICMS', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Gr√°fico 1: Evolu√ß√£o do ICMS Devido\n",
    "ax1 = axes[0, 0]\n",
    "for cnpj in df_plot['cnpj'].unique():\n",
    "    data = df_plot[df_plot['cnpj'] == cnpj]\n",
    "    ax1.plot(data['periodo'], data['vl_icms_devido'], marker='o', label=f'CNPJ {cnpj}')\n",
    "ax1.set_title('Evolu√ß√£o do ICMS Devido', fontweight='bold')\n",
    "ax1.set_xlabel('Per√≠odo')\n",
    "ax1.set_ylabel('Valor (R$)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gr√°fico 2: D√©bitos vs Cr√©ditos\n",
    "ax2 = axes[0, 1]\n",
    "periodos = df_plot['periodo'].unique()[:12]  # √öltimos 12 meses\n",
    "data_resumo = df_plot[df_plot['periodo'].isin(periodos)].groupby('periodo').agg({\n",
    "    'vl_icms_saida': 'sum',\n",
    "    'vl_icms_entrada': 'sum',\n",
    "    'vl_icms_cte': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "x = range(len(data_resumo))\n",
    "width = 0.25\n",
    "ax2.bar([i - width for i in x], data_resumo['vl_icms_saida'], width, label='D√©bito (Sa√≠da)', color='red', alpha=0.7)\n",
    "ax2.bar(x, data_resumo['vl_icms_entrada'], width, label='Cr√©dito (Entrada)', color='green', alpha=0.7)\n",
    "ax2.bar([i + width for i in x], data_resumo['vl_icms_cte'], width, label='Cr√©dito (CTe)', color='blue', alpha=0.7)\n",
    "ax2.set_title('D√©bitos vs Cr√©ditos - √öltimos 12 Meses', fontweight='bold')\n",
    "ax2.set_xlabel('Per√≠odo')\n",
    "ax2.set_ylabel('Valor (R$)')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(data_resumo['periodo'], rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Gr√°fico 3: Receita Declarada vs Receita Apurada\n",
    "ax3 = axes[1, 0]\n",
    "data_receita = df_plot.groupby('periodo').agg({\n",
    "    'bc_icms_saida': 'sum',\n",
    "    'receita_bruta_declarada': 'sum'\n",
    "}).reset_index()\n",
    "ax3.plot(data_receita['periodo'], data_receita['bc_icms_saida'], marker='o', label='BC ICMS (Apurada)', linewidth=2)\n",
    "ax3.plot(data_receita['periodo'], data_receita['receita_bruta_declarada'], marker='s', label='Receita Declarada', linewidth=2)\n",
    "ax3.fill_between(range(len(data_receita)), data_receita['bc_icms_saida'], data_receita['receita_bruta_declarada'], \n",
    "                  where=(data_receita['bc_icms_saida'] > data_receita['receita_bruta_declarada']), \n",
    "                  alpha=0.3, color='red', label='Diferen√ßa')\n",
    "ax3.set_title('Receita Declarada vs Apurada', fontweight='bold')\n",
    "ax3.set_xlabel('Per√≠odo')\n",
    "ax3.set_ylabel('Valor (R$)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gr√°fico 4: Composi√ß√£o do ICMS Devido\n",
    "ax4 = axes[1, 1]\n",
    "totais = df_plot.sum()\n",
    "componentes = ['D√©bito\\n(Sa√≠da)', 'Receita\\nOmitida', 'Declarado', 'Cr√©dito\\n(Entrada)', 'Cr√©dito\\n(CTe)']\n",
    "valores = [\n",
    "    totais['vl_icms_saida'],\n",
    "    totais['vl_icms_receita_omitida'],\n",
    "    -totais['icms_declarado'],\n",
    "    -totais['vl_icms_entrada'],\n",
    "    -totais['vl_icms_cte']\n",
    "]\n",
    "cores = ['red', 'orange', 'blue', 'green', 'cyan']\n",
    "ax4.bar(componentes, valores, color=cores, alpha=0.7)\n",
    "ax4.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax4.set_title('Composi√ß√£o do ICMS Devido (Total)', fontweight='bold')\n",
    "ax4.set_ylabel('Valor (R$)')\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estat√≠sticas resumidas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTAT√çSTICAS CONSOLIDADAS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total ICMS Devido: R$ {df_plot['vl_icms_devido'].sum():,.2f}\")\n",
    "print(f\"Total D√©bitos: R$ {df_plot['vl_icms_saida'].sum():,.2f}\")\n",
    "print(f\"Total Cr√©ditos (Entrada): R$ {df_plot['vl_icms_entrada'].sum():,.2f}\")\n",
    "print(f\"Total Cr√©ditos (CTe): R$ {df_plot['vl_icms_cte'].sum():,.2f}\")\n",
    "print(f\"Total ICMS Declarado: R$ {df_plot['icms_declarado'].sum():,.2f}\")\n",
    "print(f\"Receita N√£o Declarada: R$ {df_plot['receita_nao_declarada'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a816da-adc4-479d-85fc-a69f4e14cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# C√âLULA 13: EXPORTAR RESULTADOS PARA REDE LOCAL EM EXCEL\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPORTANDO RESULTADOS PARA REDE LOCAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import getpass\n",
    "import smbclient\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurar logging\n",
    "logging.getLogger('smbprotocol').setLevel(logging.WARNING)\n",
    "\n",
    "# ==============================================================================\n",
    "# CONFIGURA√á√ÉO DA CONEX√ÉO SMB\n",
    "# ==============================================================================\n",
    "server = \"sef.sc.gov.br\"\n",
    "user = \"tsevero\"\n",
    "\n",
    "try:\n",
    "    pwd = getpass.getpass(f\"Digite a senha de rede para {user}@{server}: \")\n",
    "    smbclient.register_session(server, username=user, password=pwd)\n",
    "    print(f\"‚úì Sess√£o SMB registrada com sucesso para {user}!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Falha ao registrar sess√£o SMB: {e}\")\n",
    "    raise\n",
    "\n",
    "# ==============================================================================\n",
    "# DEFINIR DIRET√ìRIO DE DESTINO\n",
    "# ==============================================================================\n",
    "# Criar pasta com timestamp para organizar\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "dest_dir = r\"\\\\sef.sc.gov.br\\DFS\\GERFE08\\Backup Severo\\JUPYTER\\Analise_Fiscal_NFe_CTe\"\n",
    "dest_dir_timestamped = os.path.join(dest_dir, timestamp).replace(os.sep, '\\\\')\n",
    "\n",
    "print(f\"\\nCriando pasta de destino: {dest_dir_timestamped}\")\n",
    "try:\n",
    "    if not smbclient.path.isdir(dest_dir):\n",
    "        smbclient.makedirs(dest_dir)\n",
    "    smbclient.makedirs(dest_dir_timestamped)\n",
    "    print(\"‚úì Pasta criada com sucesso\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Erro ao criar pasta: {e}\")\n",
    "    raise\n",
    "\n",
    "# ==============================================================================\n",
    "# FUN√á√ÉO PARA EXPORTAR DATAFRAME PARA EXCEL NA REDE\n",
    "# ==============================================================================\n",
    "def exportar_para_excel_rede(df_spark, nome_arquivo, caminho_destino):\n",
    "    \"\"\"\n",
    "    Exporta um DataFrame Spark para Excel na rede usando SMB\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"  Processando: {nome_arquivo}...\")\n",
    "        \n",
    "        # Converter para Pandas\n",
    "        df_pandas = df_spark.toPandas()\n",
    "        \n",
    "        if len(df_pandas) == 0:\n",
    "            print(f\"  ‚ö† DataFrame vazio, pulando: {nome_arquivo}\")\n",
    "            return False\n",
    "        \n",
    "        # Caminho completo do arquivo\n",
    "        caminho_completo = os.path.join(caminho_destino, nome_arquivo).replace(os.sep, '\\\\')\n",
    "        \n",
    "        # Criar arquivo tempor√°rio local\n",
    "        temp_file = f\"/tmp/{nome_arquivo}\"\n",
    "        \n",
    "        # Salvar como Excel localmente\n",
    "        with pd.ExcelWriter(temp_file, engine='openpyxl') as writer:\n",
    "            df_pandas.to_excel(writer, index=False, sheet_name='Dados')\n",
    "        \n",
    "        # Copiar para a rede\n",
    "        with open(temp_file, 'rb') as f_local:\n",
    "            with smbclient.open_file(caminho_completo, mode='wb') as f_remoto:\n",
    "                f_remoto.write(f_local.read())\n",
    "        \n",
    "        # Limpar arquivo tempor√°rio\n",
    "        os.remove(temp_file)\n",
    "        \n",
    "        print(f\"  ‚úì {nome_arquivo}: {len(df_pandas):,} registros exportados\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚úó Erro ao exportar {nome_arquivo}: {e}\")\n",
    "        return False\n",
    "\n",
    "# ==============================================================================\n",
    "# EXPORTAR ARQUIVOS PRINCIPAIS\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"INICIANDO EXPORTA√á√ÉO DOS ARQUIVOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "arquivos_sucesso = []\n",
    "arquivos_erro = []\n",
    "\n",
    "# 1. NOTIFICA√á√ÉO (Apura√ß√£o Mensal)\n",
    "print(\"\\n1. NOTIFICA√á√ÉO - Apura√ß√£o Mensal de ICMS\")\n",
    "if exportar_para_excel_rede(\n",
    "    spark.sql(\"SELECT * FROM vw_notificacao ORDER BY cnpj, periodo\"),\n",
    "    \"01_Notificacao.xlsx\",\n",
    "    dest_dir_timestamped\n",
    "):\n",
    "    arquivos_sucesso.append(\"01_Notificacao.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"01_Notificacao.xlsx\")\n",
    "\n",
    "# 2. ENTRADA DESTINAT√ÅRIO (Cr√©ditos)\n",
    "print(\"\\n2. ENTRADA DESTINAT√ÅRIO - Notas de Entrada (Cr√©ditos)\")\n",
    "if exportar_para_excel_rede(\n",
    "    spark.sql(\"SELECT * FROM vw_entrada_destinatario ORDER BY periodo_ref, chave_nfe\"),\n",
    "    \"02_Entrada_Destinatario.xlsx\",\n",
    "    dest_dir_timestamped\n",
    "):\n",
    "    arquivos_sucesso.append(\"02_Entrada_Destinatario.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"02_Entrada_Destinatario.xlsx\")\n",
    "\n",
    "# 3. SA√çDA EMITENTE (D√©bitos)\n",
    "print(\"\\n3. SA√çDA EMITENTE - Notas de Sa√≠da (D√©bitos)\")\n",
    "if exportar_para_excel_rede(\n",
    "    spark.sql(\"SELECT * FROM vw_saida_emitente ORDER BY periodo_ref, chave_nfe\"),\n",
    "    \"03_Saida_Emitente.xlsx\",\n",
    "    dest_dir_timestamped\n",
    "):\n",
    "    arquivos_sucesso.append(\"03_Saida_Emitente.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"03_Saida_Emitente.xlsx\")\n",
    "\n",
    "# 4. CTe (Cr√©dito de Frete)\n",
    "print(\"\\n4. CTe - Conhecimento de Transporte\")\n",
    "if exportar_para_excel_rede(\n",
    "    spark.sql(\"SELECT * FROM vw_cte_filtrado ORDER BY periodo_ref, chave_cte\"),\n",
    "    \"04_CTe.xlsx\",\n",
    "    dest_dir_timestamped\n",
    "):\n",
    "    arquivos_sucesso.append(\"04_CTe.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"04_CTe.xlsx\")\n",
    "\n",
    "# 5. PGDAS-D (Simples Nacional)\n",
    "print(\"\\n5. PGDAS-D - Declara√ß√µes Simples Nacional\")\n",
    "if exportar_para_excel_rede(\n",
    "    spark.sql(\"SELECT * FROM vw_pgdas_filtrado ORDER BY cnpj, periodo_ref\"),\n",
    "    \"05_PGDAS_D.xlsx\",\n",
    "    dest_dir_timestamped\n",
    "):\n",
    "    arquivos_sucesso.append(\"05_PGDAS_D.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"05_PGDAS_D.xlsx\")\n",
    "\n",
    "# 6. RESUMO POR CNPJ\n",
    "print(\"\\n6. RESUMO POR CNPJ\")\n",
    "df_resumo_cnpj = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        cnpj,\n",
    "        COUNT(DISTINCT periodo) as qtde_periodos,\n",
    "        ROUND(SUM(vl_icms_saida), 2) as total_debitos,\n",
    "        ROUND(SUM(vl_icms_entrada), 2) as total_creditos_entrada,\n",
    "        ROUND(SUM(vl_icms_cte), 2) as total_creditos_cte,\n",
    "        ROUND(SUM(icms_declarado), 2) as total_declarado,\n",
    "        ROUND(SUM(vl_icms_devido), 2) as total_devido,\n",
    "        ROUND(SUM(receita_nao_declarada), 2) as total_receita_omitida\n",
    "    FROM vw_notificacao\n",
    "    GROUP BY cnpj\n",
    "\"\"\")\n",
    "\n",
    "if exportar_para_excel_rede(df_resumo_cnpj, \"06_Resumo_por_CNPJ.xlsx\", dest_dir_timestamped):\n",
    "    arquivos_sucesso.append(\"06_Resumo_por_CNPJ.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"06_Resumo_por_CNPJ.xlsx\")\n",
    "\n",
    "# 7. TOP CFOPs\n",
    "print(\"\\n7. TOP CFOPs\")\n",
    "df_top_cfops = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        cfop,\n",
    "        descricaocfop,\n",
    "        entrada_saida,\n",
    "        conta,\n",
    "        COUNT(*) as qtde_itens,\n",
    "        ROUND(SUM(valor_produto), 2) as valor_total\n",
    "    FROM vw_nfe_com_icms\n",
    "    GROUP BY cfop, descricaocfop, entrada_saida, conta\n",
    "    ORDER BY qtde_itens DESC\n",
    "    LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "if exportar_para_excel_rede(df_top_cfops, \"07_Top_CFOPs.xlsx\", dest_dir_timestamped):\n",
    "    arquivos_sucesso.append(\"07_Top_CFOPs.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"07_Top_CFOPs.xlsx\")\n",
    "\n",
    "# 8. TOP PRODUTOS\n",
    "print(\"\\n8. TOP PRODUTOS\")\n",
    "df_top_produtos = spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        descricao_produto,\n",
    "        ncm,\n",
    "        COUNT(*) as qtde_vendas,\n",
    "        ROUND(SUM(valor_produto), 2) as valor_total\n",
    "    FROM vw_nfe_com_icms\n",
    "    WHERE entrada_saida = 'Saida' AND emitente_no_cadastro = 1\n",
    "    GROUP BY descricao_produto, ncm\n",
    "    ORDER BY valor_total DESC\n",
    "    LIMIT 100\n",
    "\"\"\")\n",
    "\n",
    "if exportar_para_excel_rede(df_top_produtos, \"08_Top_Produtos.xlsx\", dest_dir_timestamped):\n",
    "    arquivos_sucesso.append(\"08_Top_Produtos.xlsx\")\n",
    "else:\n",
    "    arquivos_erro.append(\"08_Top_Produtos.xlsx\")\n",
    "\n",
    "# ==============================================================================\n",
    "# RELAT√ìRIO FINAL\n",
    "# ==============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RELAT√ìRIO DE EXPORTA√á√ÉO\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nPasta de destino: {dest_dir_timestamped}\")\n",
    "print(f\"\\nArquivos exportados com sucesso: {len(arquivos_sucesso)}\")\n",
    "for arq in arquivos_sucesso:\n",
    "    print(f\"  ‚úì {arq}\")\n",
    "\n",
    "if arquivos_erro:\n",
    "    print(f\"\\nArquivos com erro: {len(arquivos_erro)}\")\n",
    "    for arq in arquivos_erro:\n",
    "        print(f\"  ‚úó {arq}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXPORTA√á√ÉO CONCLU√çDA!\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Pipeline)",
   "language": "python",
   "name": "conda_data_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
