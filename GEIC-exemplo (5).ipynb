{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aea681-2477-45f5-9ffe-1cb8f6cb1a68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/poc\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/plugins\")\n",
    "sys.path.append(\"/home/tsevero/notebooks/SAT_BIG_DATA/data-pipeline/batch/dags\")\n",
    "\n",
    "#Import libs python\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import date\n",
    "\n",
    "#Import libs internas\n",
    "from utils import spark_utils_session as utils\n",
    "\n",
    "from hooks.hdfs.hdfs_helper import HdfsHelper\n",
    "from jobs.job_base_config import BaseETLJobClass\n",
    "\n",
    "import poc_helper\n",
    "poc_helper.load_env(\"PROD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faf8a1f-48e4-4c57-a162-c839c8e3a940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_session(profile: str, dynamic_allocation_enabled: bool = True) -> utils.DBASparkAppSession:\n",
    "    \"\"\"Generates DBASparkAppSession.\"\"\"\n",
    "    \n",
    "    app_name = \"tsevero_gei\"\n",
    "    \n",
    "    spark_builder = (utils.DBASparkAppSession\n",
    "                     .builder\n",
    "                     .setAppName(app_name)\n",
    "                     .usingProcessProfile(profile)\n",
    "                    )\n",
    "    \n",
    "    if dynamic_allocation_enabled:\n",
    "        spark_builder.autoResourceManagement()\n",
    "\n",
    "    return spark_builder.build()\n",
    "\n",
    "session = get_session(profile='efd_t2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00777b24-69dc-4a6e-ba6f-4e11cd534937",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sparkSession.sql(\"SHOW DATABASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d8bf8-a229-46d4-8c06-850c68566574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas para análise e visualização\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (16, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Acesso ao SparkSession\n",
    "spark = session.sparkSession\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SISTEMA DE ANÁLISE GEI - Gestão de Empresas e Indícios Fiscais\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Sessão Spark: {spark.sparkContext.appName}\")\n",
    "print(f\"Versão Spark: {spark.version}\")\n",
    "print(f\"Iniciado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb6645-d9a0-4600-8a23-8d6fd4bb330e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICAÇÃO DE TABELAS DISPONÍVEIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Lista de tabelas esperadas\n",
    "tabelas_esperadas = [\n",
    "    'gessimples.gei_percent',\n",
    "    'gessimples.gei_cnpj',\n",
    "    'gessimples.gei_nfe_completo',\n",
    "    'gessimples.gei_cadastro',\n",
    "    'gessimples.gei_contador',\n",
    "    'gessimples.gei_socios_metricas',\n",
    "    'gessimples.gei_c115_ranking_risco_grupo_economico',\n",
    "    'gessimples.gei_indicios_metricas_grupo',\n",
    "    'gessimples.gei_pagamentos_metricas_grupo',\n",
    "    'gessimples.gei_funcionarios_metricas_grupo'\n",
    "]\n",
    "\n",
    "print(\"\\nVerificando tabelas do sistema GEI:\\n\")\n",
    "for tabela in tabelas_esperadas:\n",
    "    try:\n",
    "        count = spark.sql(f\"SELECT COUNT(*) as cnt FROM {tabela}\").collect()[0]['cnt']\n",
    "        print(f\"✓ {tabela:60s} -> {count:,} registros\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {tabela:60s} -> NÃO ENCONTRADA\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17742d-e289-45f6-9fcc-d2fc7b14f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"1. PANORAMA GERAL DO SISTEMA GEI\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_panorama = \"\"\"\n",
    "SELECT \n",
    "    COUNT(DISTINCT num_grupo) AS total_grupos,\n",
    "    SUM(qntd_cnpj) AS total_cnpjs,\n",
    "    ROUND(AVG(score_final_avancado), 2) AS score_medio,\n",
    "    ROUND(MAX(score_final_avancado), 2) AS score_maximo,\n",
    "    COUNT(CASE WHEN score_final_avancado >= 20 THEN 1 END) AS grupos_criticos,\n",
    "    COUNT(CASE WHEN score_final_avancado >= 15 AND score_final_avancado < 20 THEN 1 END) AS grupos_alto_risco,\n",
    "    COUNT(CASE WHEN score_final_avancado >= 10 AND score_final_avancado < 15 THEN 1 END) AS grupos_medio_risco,\n",
    "    SUM(COALESCE(valor_max, 0)) AS receita_total_monitorada,\n",
    "    COUNT(CASE WHEN valor_max >= 4800000 THEN 1 END) AS grupos_acima_limite_sn\n",
    "FROM gessimples.gei_percent\n",
    "\"\"\"\n",
    "\n",
    "df_panorama = spark.sql(query_panorama)\n",
    "panorama = df_panorama.collect()[0]\n",
    "\n",
    "print(f\"\\nMÉTRICAS PRINCIPAIS:\")\n",
    "print(f\"  Total de Grupos Monitorados: {panorama['total_grupos']:,}\")\n",
    "print(f\"  Total de CNPJs: {panorama['total_cnpjs']:,}\")\n",
    "print(f\"  Score Médio de Risco: {panorama['score_medio']:.2f}\")\n",
    "print(f\"  Score Máximo Detectado: {panorama['score_maximo']:.2f}\")\n",
    "print(f\"\\nDISTRIBUIÇÃO DE RISCO:\")\n",
    "print(f\"  Grupos Críticos (≥20): {panorama['grupos_criticos']:,}\")\n",
    "print(f\"  Grupos Alto Risco (15-20): {panorama['grupos_alto_risco']:,}\")\n",
    "print(f\"  Grupos Médio Risco (10-15): {panorama['grupos_medio_risco']:,}\")\n",
    "print(f\"\\nIMPACTO FINANCEIRO:\")\n",
    "print(f\"  Receita Total Monitorada: R$ {panorama['receita_total_monitorada']:,.2f}\")\n",
    "print(f\"  Grupos Acima Limite SN: {panorama['grupos_acima_limite_sn']:,}\")\n",
    "\n",
    "# Gráfico de Distribuição por Faixa de Risco\n",
    "dist_risco = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    CASE \n",
    "        WHEN score_final_avancado >= 25 THEN 'Crítico Extremo (≥25)'\n",
    "        WHEN score_final_avancado >= 20 THEN 'Crítico (20-25)'\n",
    "        WHEN score_final_avancado >= 15 THEN 'Alto (15-20)'\n",
    "        WHEN score_final_avancado >= 10 THEN 'Médio (10-15)'\n",
    "        WHEN score_final_avancado >= 5 THEN 'Baixo (5-10)'\n",
    "        ELSE 'Mínimo (<5)'\n",
    "    END AS faixa_risco,\n",
    "    COUNT(*) AS quantidade,\n",
    "    SUM(COALESCE(valor_max, 0)) AS bc_total\n",
    "FROM gessimples.gei_percent\n",
    "GROUP BY 1\n",
    "ORDER BY MIN(score_final_avancado) DESC\n",
    "\"\"\").toPandas()\n",
    "\n",
    "dist_risco['bc_total'] = dist_risco['bc_total'].astype(float)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "fig.suptitle('Distribuição de Grupos por Faixa de Risco', fontsize=16, fontweight='bold')\n",
    "\n",
    "colors = ['#d62728', '#ff7f0e', '#ffdd70', '#8c564b', '#1f77b4', '#2ca02c']\n",
    "ax1.pie(dist_risco['quantidade'], labels=dist_risco['faixa_risco'], autopct='%1.1f%%',\n",
    "        colors=colors, startangle=90)\n",
    "ax1.set_title('Percentual de Grupos')\n",
    "\n",
    "ax2.barh(dist_risco['faixa_risco'], dist_risco['bc_total']/1e6, color=colors)\n",
    "ax2.set_xlabel('Base de Cálculo Total (Milhões R$)')\n",
    "ax2.set_title('Impacto Financeiro por Faixa')\n",
    "ax2.invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc71eff-8614-4adf-aec9-a9e1b2eff84d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"2. RANKING: TOP 30 GRUPOS DE MAIOR RISCO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "query_ranking = \"\"\"\n",
    "SELECT \n",
    "    num_grupo,\n",
    "    qntd_cnpj,\n",
    "    score_final_avancado,\n",
    "    valor_max,\n",
    "    total_funcionarios,\n",
    "    nivel_risco_grupo_economico,\n",
    "    \n",
    "    -- Componentes individuais do score\n",
    "    total as score_inconsistencias,\n",
    "    indice_interconexao,\n",
    "    indice_risco_grupo_economico,\n",
    "    indice_risco_indicios,\n",
    "    indice_risco_pagamentos,\n",
    "    indice_risco_fat_func\n",
    "    \n",
    "FROM gessimples.gei_percent\n",
    "WHERE score_final_avancado IS NOT NULL\n",
    "ORDER BY score_final_avancado DESC\n",
    "LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "df_ranking = spark.sql(query_ranking).toPandas()\n",
    "\n",
    "# Converter Decimal para float\n",
    "numeric_cols = ['valor_max', 'score_final_avancado', 'indice_interconexao', \n",
    "                'indice_risco_grupo_economico', 'indice_risco_indicios',\n",
    "                'indice_risco_pagamentos', 'indice_risco_fat_func']\n",
    "for col in numeric_cols:\n",
    "    if col in df_ranking.columns:\n",
    "        df_ranking[col] = pd.to_numeric(df_ranking[col], errors='coerce')\n",
    "\n",
    "print(\"\\nTOP 30 GRUPOS POR SCORE DE RISCO:\\n\")\n",
    "for idx, row in df_ranking.iterrows():\n",
    "    print(f\"{idx+1:2d}. Grupo {row['num_grupo']}\")\n",
    "    print(f\"    Score Final: {row['score_final_avancado']:.2f} | CNPJs: {int(row['qntd_cnpj'])}\")\n",
    "    print(f\"    Receita: R$ {row['valor_max']:,.2f} | Funcionários: {int(row['total_funcionarios'])}\")\n",
    "    print(f\"    Nível Risco C115: {row['nivel_risco_grupo_economico'] or 'INEXISTENTE'}\")\n",
    "    print()\n",
    "\n",
    "# Visualização - Heatmap de componentes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle('Análise de Risco - Top 30 Grupos', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Preparar dados para heatmap (Top 15)\n",
    "risk_components = df_ranking.head(15)[['score_inconsistencias', 'indice_interconexao', \n",
    "                                        'indice_risco_grupo_economico', 'indice_risco_indicios',\n",
    "                                        'indice_risco_pagamentos', 'indice_risco_fat_func']].fillna(0)\n",
    "risk_components.index = df_ranking.head(15)['num_grupo'].astype(str)\n",
    "\n",
    "# Normalizar para visualização\n",
    "risk_components_norm = risk_components.copy()\n",
    "for col in risk_components_norm.columns:\n",
    "    col_min = risk_components_norm[col].min()\n",
    "    col_max = risk_components_norm[col].max()\n",
    "    if col_max > col_min:\n",
    "        risk_components_norm[col] = (risk_components_norm[col] - col_min) / (col_max - col_min)\n",
    "    else:\n",
    "        risk_components_norm[col] = 0\n",
    "\n",
    "sns.heatmap(risk_components_norm.T, annot=True, fmt='.2f', cmap='YlOrRd',\n",
    "            cbar_kws={'label': 'Índice Normalizado (0-1)'}, linewidths=0.5, ax=ax1)\n",
    "ax1.set_title('Composição do Risco - Top 15 Grupos')\n",
    "ax1.set_xlabel('Grupo')\n",
    "ax1.set_ylabel('Componente de Risco')\n",
    "\n",
    "# Gráfico de barras do score final\n",
    "top15 = df_ranking.head(15).sort_values('score_final_avancado', ascending=True)\n",
    "colors_risk = ['#8b0000' if x >= 90 else '#d62728' if x >= 80 else '#ff7f0e' \n",
    "               for x in top15['score_final_avancado']]\n",
    "ax2.barh(top15['num_grupo'].astype(str), top15['score_final_avancado'], color=colors_risk)\n",
    "ax2.set_xlabel('Score Final de Risco')\n",
    "ax2.set_ylabel('Grupo')\n",
    "ax2.set_title('Score Final - Top 15 Grupos')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Data Pipeline)",
   "language": "python",
   "name": "conda_data_pipeline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
